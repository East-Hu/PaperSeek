"""
PDF ä¸‹è½½æ¨¡å— - ç”¨äºä¸‹è½½ ArXiv è®ºæ–‡ PDF
"""
import requests
import os
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
import time

console = Console()


@dataclass
class DownloadResult:
    """å•ä¸ª PDF ä¸‹è½½ç»“æœ"""
    paper_id: str
    title: str
    success: bool
    file_path: Optional[str] = None
    error: Optional[str] = None
    url: Optional[str] = None


@dataclass
class DownloadStats:
    """æ‰¹é‡ä¸‹è½½ç»Ÿè®¡"""
    total: int
    successful: int
    failed: int
    results: List[DownloadResult]


class PDFDownloader:
    """ArXiv PDF ä¸‹è½½å™¨"""
    
    def __init__(self, output_dir: str = "papers/pdfs", timeout: int = 30, max_retries: int = 3):
        """
        åˆå§‹åŒ– PDF ä¸‹è½½å™¨
        
        Args:
            output_dir: PDF ä¿å­˜ç›®å½•
            timeout: ä¸‹è½½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.output_dir = output_dir
        self.timeout = timeout
        self.max_retries = max_retries
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
    
    def get_pdf_url(self, arxiv_id: str) -> str:
        """
        è·å– ArXiv PDF URL
        
        Args:
            arxiv_id: ArXiv ID (ä¾‹å¦‚: 2301.01234 æˆ– abs/2301.01234)
            
        Returns:
            PDF URL
        """
        # æ¸…ç† arxiv_id
        arxiv_id = arxiv_id.replace('http://arxiv.org/', '')
        arxiv_id = arxiv_id.replace('https://arxiv.org/', '')
        arxiv_id = arxiv_id.replace('abs/', '')
        arxiv_id = arxiv_id.replace('pdf/', '')
        arxiv_id = arxiv_id.replace('.pdf', '')
        
        return f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    def sanitize_filename(self, title: str, arxiv_id: str) -> str:
        """
        ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        
        Args:
            title: è®ºæ–‡æ ‡é¢˜
            arxiv_id: ArXiv ID
            
        Returns:
            å®‰å…¨çš„æ–‡ä»¶å
        """
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
        # é™åˆ¶é•¿åº¦
        safe_title = safe_title[:50]
        # æ¸…ç† arxiv_id
        clean_id = arxiv_id.split('/')[-1].replace('.pdf', '')
        
        return f"{clean_id}_{safe_title}.pdf"
    
    def download_with_retry(self, url: str, filepath: str) -> Tuple[bool, Optional[str]]:
        """
        å¸¦é‡è¯•çš„ä¸‹è½½
        
        Args:
            url: ä¸‹è½½ URL
            filepath: ä¿å­˜è·¯å¾„
            
        Returns:
            (æˆåŠŸä¸å¦, é”™è¯¯ä¿¡æ¯)
        """
        for attempt in range(self.max_retries):
            try:
                response = requests.get(
                    url,
                    timeout=self.timeout,
                    headers={'User-Agent': 'Mozilla/5.0 (PaperSeek Bot)'},
                    stream=True
                )
                
                if response.status_code == 200:
                    # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ PDF
                    content_type = response.headers.get('Content-Type', '')
                    if 'application/pdf' not in content_type:
                        return False, f"å“åº”ä¸æ˜¯ PDF æ–‡ä»¶ (Content-Type: {content_type})"
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                    
                    # éªŒè¯æ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(filepath)
                    if file_size < 1000:  # å°äº 1KB å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                        os.remove(filepath)
                        return False, f"æ–‡ä»¶è¿‡å° ({file_size} bytes)ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ PDF"
                    
                    return True, None
                
                elif response.status_code == 404:
                    return False, "PDF ä¸å­˜åœ¨ (404)"
                
                elif response.status_code == 403:
                    return False, "è®¿é—®è¢«æ‹’ç» (403)"
                
                else:
                    error_msg = f"HTTP {response.status_code}"
                    if attempt < self.max_retries - 1:
                        wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                        time.sleep(wait_time)
                        continue
                    return False, error_msg
                    
            except requests.exceptions.Timeout:
                error_msg = "ä¸‹è½½è¶…æ—¶"
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    time.sleep(wait_time)
                    continue
                return False, error_msg
                
            except requests.exceptions.ConnectionError:
                error_msg = "è¿æ¥å¤±è´¥"
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    time.sleep(wait_time)
                    continue
                return False, error_msg
                
            except Exception as e:
                return False, f"æœªçŸ¥é”™è¯¯: {str(e)}"
        
        return False, f"é‡è¯• {self.max_retries} æ¬¡åä»ç„¶å¤±è´¥"
    
    def download_paper(self, paper: Dict) -> DownloadResult:
        """
        ä¸‹è½½å•ç¯‡è®ºæ–‡çš„ PDF
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯å­—å…¸
            
        Returns:
            ä¸‹è½½ç»“æœ
        """
        arxiv_id = paper.get('arxiv_id', '')
        title = paper.get('title', 'untitled')
        
        if not arxiv_id:
            return DownloadResult(
                paper_id=arxiv_id,
                title=title,
                success=False,
                error="ç¼ºå°‘ ArXiv ID"
            )
        
        # ç”Ÿæˆ URL å’Œæ–‡ä»¶è·¯å¾„
        pdf_url = self.get_pdf_url(arxiv_id)
        filename = self.sanitize_filename(title, arxiv_id)
        filepath = os.path.join(self.output_dir, filename)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(filepath):
            return DownloadResult(
                paper_id=arxiv_id,
                title=title,
                success=True,
                file_path=filepath,
                url=pdf_url
            )
        
        # ä¸‹è½½
        success, error = self.download_with_retry(pdf_url, filepath)
        
        return DownloadResult(
            paper_id=arxiv_id,
            title=title,
            success=success,
            file_path=filepath if success else None,
            error=error,
            url=pdf_url
        )
    
    def batch_download(
        self, 
        papers: List[Dict], 
        progress_callback=None
    ) -> DownloadStats:
        """
        æ‰¹é‡ä¸‹è½½è®ºæ–‡ PDF
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current, total) å‚æ•°
            
        Returns:
            ä¸‹è½½ç»Ÿè®¡
        """
        results = []
        successful = 0
        failed = 0
        
        for i, paper in enumerate(papers, 1):
            result = self.download_paper(paper)
            results.append(result)
            
            if result.success:
                successful += 1
            else:
                failed += 1
            
            # å›è°ƒè¿›åº¦
            if progress_callback:
                progress_callback(i)
            
            # å°å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«è¯·æ±‚
            if i < len(papers):
                time.sleep(0.5)
        
        return DownloadStats(
            total=len(papers),
            successful=successful,
            failed=failed,
            results=results
        )
    
    def print_download_report(self, stats: DownloadStats):
        """
        æ‰“å°ä¸‹è½½æŠ¥å‘Š
        
        Args:
            stats: ä¸‹è½½ç»Ÿè®¡
        """
        console.print("\n" + "="*60)
        console.print(f"[bold bright_cyan]ğŸ“Š ä¸‹è½½ç»Ÿè®¡æŠ¥å‘Š[/bold bright_cyan]\n")
        
        console.print(f"[cyan]æ€»è®¡å°è¯•:[/cyan] {stats.total} ç¯‡")
        console.print(f"[green]æˆåŠŸä¸‹è½½:[/green] {stats.successful} ç¯‡ âœ“")
        console.print(f"[red]ä¸‹è½½å¤±è´¥:[/red] {stats.failed} ç¯‡ âœ—")
        
        if stats.failed > 0:
            console.print(f"\n[yellow]âŒ ä¸‹è½½å¤±è´¥çš„è®ºæ–‡:[/yellow]\n")
            
            for i, result in enumerate([r for r in stats.results if not r.success], 1):
                console.print(f"  {i}. [bold]{result.title[:60]}...[/bold]")
                console.print(f"     [dim]åŸå› :[/dim] {result.error}")
                console.print(f"     [dim]é“¾æ¥:[/dim] {result.url}")
                console.print()
        
        if stats.successful > 0:
            console.print(f"\n[green]âœ“ æˆåŠŸä¸‹è½½çš„ PDF å·²ä¿å­˜åˆ°:[/green]")
            console.print(f"  [cyan]{self.output_dir}/[/cyan]")
        
        console.print("="*60 + "\n")
